{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6546c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage import color,io\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54449bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0188bd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c0d3085460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(x_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884cc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def togray(image):    \n",
    "    im = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    im = np.reshape(im, (im.shape[0], im.shape[1], 1))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "raw",
   "id": "152f14c7",
   "metadata": {},
   "source": [
    "x_train = np.array([togray(image) for image in x_train]) \n",
    "x_test = np.array([togray(image) for image in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e273ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf956442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model():\n",
    "    \n",
    "    # Input layer\n",
    "    input_shape = (32,32,3)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation=\"relu\", input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128,activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout((0.2)),\n",
    "        keras.layers.Dense(128,activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout((0.2)),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fdcee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 15, 15, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          4128      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3, 3, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               36992     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,322\n",
      "Trainable params: 60,746\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = CNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e4a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, mode=\"auto\")\n",
    "best_model_file = \"CIFAR.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor=\"val_accuracy\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbd5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train):    \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train,y_train, validation_split=0.2, epochs=100, verbose=1, batch_size=128, callbacks=[best_model])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdf92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 2.4083 - accuracy: 0.2185\n",
      "Epoch 1: val_accuracy improved from -inf to 0.19990, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 14s 27ms/step - loss: 2.4083 - accuracy: 0.2185 - val_loss: 2.2914 - val_accuracy: 0.1999\n",
      "Epoch 2/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.9138 - accuracy: 0.3369\n",
      "Epoch 2: val_accuracy improved from 0.19990 to 0.38620, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.9136 - accuracy: 0.3370 - val_loss: 1.7130 - val_accuracy: 0.3862\n",
      "Epoch 3/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.7194 - accuracy: 0.3933\n",
      "Epoch 3: val_accuracy improved from 0.38620 to 0.46240, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.7190 - accuracy: 0.3934 - val_loss: 1.4979 - val_accuracy: 0.4624\n",
      "Epoch 4/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5840 - accuracy: 0.4383\n",
      "Epoch 4: val_accuracy improved from 0.46240 to 0.49800, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.5840 - accuracy: 0.4384 - val_loss: 1.4061 - val_accuracy: 0.4980\n",
      "Epoch 5/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4788 - accuracy: 0.4751\n",
      "Epoch 5: val_accuracy improved from 0.49800 to 0.52930, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 1.4791 - accuracy: 0.4750 - val_loss: 1.3258 - val_accuracy: 0.5293\n",
      "Epoch 6/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.3986 - accuracy: 0.4980\n",
      "Epoch 6: val_accuracy improved from 0.52930 to 0.54070, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.3983 - accuracy: 0.4981 - val_loss: 1.2849 - val_accuracy: 0.5407\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.3333 - accuracy: 0.5238\n",
      "Epoch 7: val_accuracy improved from 0.54070 to 0.56460, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.3333 - accuracy: 0.5238 - val_loss: 1.2194 - val_accuracy: 0.5646\n",
      "Epoch 8/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.2794 - accuracy: 0.5463\n",
      "Epoch 8: val_accuracy improved from 0.56460 to 0.57510, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.2796 - accuracy: 0.5463 - val_loss: 1.1945 - val_accuracy: 0.5751\n",
      "Epoch 9/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.2394 - accuracy: 0.5602\n",
      "Epoch 9: val_accuracy improved from 0.57510 to 0.57970, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.2397 - accuracy: 0.5601 - val_loss: 1.1779 - val_accuracy: 0.5797\n",
      "Epoch 10/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.1976 - accuracy: 0.5733\n",
      "Epoch 10: val_accuracy improved from 0.57970 to 0.59370, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 1.1974 - accuracy: 0.5734 - val_loss: 1.1519 - val_accuracy: 0.5937\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.1640 - accuracy: 0.5903\n",
      "Epoch 11: val_accuracy improved from 0.59370 to 0.59790, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.1640 - accuracy: 0.5903 - val_loss: 1.1337 - val_accuracy: 0.5979\n",
      "Epoch 12/100\n",
      "308/313 [============================>.] - ETA: 0s - loss: 1.1383 - accuracy: 0.5959\n",
      "Epoch 12: val_accuracy improved from 0.59790 to 0.60880, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.1380 - accuracy: 0.5960 - val_loss: 1.1102 - val_accuracy: 0.6088\n",
      "Epoch 13/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.1133 - accuracy: 0.6051\n",
      "Epoch 13: val_accuracy improved from 0.60880 to 0.60950, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 1.1128 - accuracy: 0.6052 - val_loss: 1.1065 - val_accuracy: 0.6095\n",
      "Epoch 14/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.0889 - accuracy: 0.6129\n",
      "Epoch 14: val_accuracy improved from 0.60950 to 0.62670, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.0890 - accuracy: 0.6129 - val_loss: 1.0529 - val_accuracy: 0.6267\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.0663 - accuracy: 0.6236\n",
      "Epoch 15: val_accuracy improved from 0.62670 to 0.63640, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.0663 - accuracy: 0.6236 - val_loss: 1.0325 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.0381 - accuracy: 0.6338\n",
      "Epoch 16: val_accuracy improved from 0.63640 to 0.63790, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.0381 - accuracy: 0.6338 - val_loss: 1.0187 - val_accuracy: 0.6379\n",
      "Epoch 17/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.0227 - accuracy: 0.6405\n",
      "Epoch 17: val_accuracy improved from 0.63790 to 0.63930, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.0227 - accuracy: 0.6404 - val_loss: 1.0206 - val_accuracy: 0.6393\n",
      "Epoch 18/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.0074 - accuracy: 0.6454\n",
      "Epoch 18: val_accuracy improved from 0.63930 to 0.63950, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.0073 - accuracy: 0.6453 - val_loss: 1.0170 - val_accuracy: 0.6395\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.9875 - accuracy: 0.6507\n",
      "Epoch 19: val_accuracy improved from 0.63950 to 0.64820, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.9875 - accuracy: 0.6507 - val_loss: 1.0005 - val_accuracy: 0.6482\n",
      "Epoch 20/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.9764 - accuracy: 0.6554\n",
      "Epoch 20: val_accuracy improved from 0.64820 to 0.65100, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.9759 - accuracy: 0.6555 - val_loss: 0.9976 - val_accuracy: 0.6510\n",
      "Epoch 21/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9556 - accuracy: 0.6654\n",
      "Epoch 21: val_accuracy did not improve from 0.65100\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.9560 - accuracy: 0.6652 - val_loss: 1.0160 - val_accuracy: 0.6371\n",
      "Epoch 22/100\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.9431 - accuracy: 0.6700\n",
      "Epoch 22: val_accuracy improved from 0.65100 to 0.65860, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.9433 - accuracy: 0.6698 - val_loss: 0.9661 - val_accuracy: 0.6586\n",
      "Epoch 23/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.6705\n",
      "Epoch 23: val_accuracy did not improve from 0.65860\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.9299 - accuracy: 0.6706 - val_loss: 0.9891 - val_accuracy: 0.6497\n",
      "Epoch 24/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.9142 - accuracy: 0.6775\n",
      "Epoch 24: val_accuracy improved from 0.65860 to 0.66620, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.9146 - accuracy: 0.6772 - val_loss: 0.9445 - val_accuracy: 0.6662\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.9027 - accuracy: 0.6832\n",
      "Epoch 25: val_accuracy improved from 0.66620 to 0.67250, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.9027 - accuracy: 0.6832 - val_loss: 0.9302 - val_accuracy: 0.6725\n",
      "Epoch 26/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.8889 - accuracy: 0.6870\n",
      "Epoch 26: val_accuracy did not improve from 0.67250\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.8886 - accuracy: 0.6870 - val_loss: 0.9302 - val_accuracy: 0.6692\n",
      "Epoch 27/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.8802 - accuracy: 0.6937\n",
      "Epoch 27: val_accuracy did not improve from 0.67250\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.8799 - accuracy: 0.6938 - val_loss: 1.0151 - val_accuracy: 0.6420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.8740 - accuracy: 0.6949\n",
      "Epoch 28: val_accuracy improved from 0.67250 to 0.67910, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.8740 - accuracy: 0.6949 - val_loss: 0.9124 - val_accuracy: 0.6791\n",
      "Epoch 29/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8586 - accuracy: 0.6984\n",
      "Epoch 29: val_accuracy did not improve from 0.67910\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.8585 - accuracy: 0.6985 - val_loss: 0.9308 - val_accuracy: 0.6752\n",
      "Epoch 30/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8472 - accuracy: 0.7018\n",
      "Epoch 30: val_accuracy improved from 0.67910 to 0.68730, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.8474 - accuracy: 0.7017 - val_loss: 0.8977 - val_accuracy: 0.6873\n",
      "Epoch 31/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8384 - accuracy: 0.7061\n",
      "Epoch 31: val_accuracy did not improve from 0.68730\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.8385 - accuracy: 0.7061 - val_loss: 0.9416 - val_accuracy: 0.6680\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.8248 - accuracy: 0.7104\n",
      "Epoch 32: val_accuracy improved from 0.68730 to 0.68820, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.8248 - accuracy: 0.7104 - val_loss: 0.8858 - val_accuracy: 0.6882\n",
      "Epoch 33/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.8196 - accuracy: 0.7136\n",
      "Epoch 33: val_accuracy did not improve from 0.68820\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.8198 - accuracy: 0.7135 - val_loss: 0.9279 - val_accuracy: 0.6754\n",
      "Epoch 34/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8115 - accuracy: 0.7155\n",
      "Epoch 34: val_accuracy improved from 0.68820 to 0.69130, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.8114 - accuracy: 0.7155 - val_loss: 0.8802 - val_accuracy: 0.6913\n",
      "Epoch 35/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.8063 - accuracy: 0.7182\n",
      "Epoch 35: val_accuracy did not improve from 0.69130\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.8057 - accuracy: 0.7184 - val_loss: 0.9140 - val_accuracy: 0.6726\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.7209\n",
      "Epoch 36: val_accuracy did not improve from 0.69130\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.7939 - accuracy: 0.7209 - val_loss: 0.9400 - val_accuracy: 0.6698\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.7247\n",
      "Epoch 37: val_accuracy improved from 0.69130 to 0.69330, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.7823 - accuracy: 0.7247 - val_loss: 0.8753 - val_accuracy: 0.6933\n",
      "Epoch 38/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.7274\n",
      "Epoch 38: val_accuracy did not improve from 0.69330\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.7771 - accuracy: 0.7274 - val_loss: 0.9400 - val_accuracy: 0.6725\n",
      "Epoch 39/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.7687 - accuracy: 0.7319\n",
      "Epoch 39: val_accuracy did not improve from 0.69330\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.7693 - accuracy: 0.7316 - val_loss: 0.9236 - val_accuracy: 0.6771\n",
      "Epoch 40/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.7631 - accuracy: 0.7335\n",
      "Epoch 40: val_accuracy improved from 0.69330 to 0.69440, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.7634 - accuracy: 0.7333 - val_loss: 0.8733 - val_accuracy: 0.6944\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.7359\n",
      "Epoch 41: val_accuracy improved from 0.69440 to 0.69610, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.7602 - accuracy: 0.7359 - val_loss: 0.8669 - val_accuracy: 0.6961\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7467 - accuracy: 0.7379\n",
      "Epoch 42: val_accuracy improved from 0.69610 to 0.69970, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.7467 - accuracy: 0.7379 - val_loss: 0.8600 - val_accuracy: 0.6997\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7432 - accuracy: 0.7384\n",
      "Epoch 43: val_accuracy did not improve from 0.69970\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.7432 - accuracy: 0.7384 - val_loss: 0.8580 - val_accuracy: 0.6992\n",
      "Epoch 44/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7362 - accuracy: 0.7408\n",
      "Epoch 44: val_accuracy did not improve from 0.69970\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.7361 - accuracy: 0.7408 - val_loss: 0.8759 - val_accuracy: 0.6906\n",
      "Epoch 45/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7271 - accuracy: 0.7457\n",
      "Epoch 45: val_accuracy did not improve from 0.69970\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.7274 - accuracy: 0.7455 - val_loss: 0.8639 - val_accuracy: 0.6969\n",
      "Epoch 46/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.7259 - accuracy: 0.7451\n",
      "Epoch 46: val_accuracy did not improve from 0.69970\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7260 - accuracy: 0.7451 - val_loss: 0.8628 - val_accuracy: 0.6961\n",
      "Epoch 47/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.7172 - accuracy: 0.7487\n",
      "Epoch 47: val_accuracy did not improve from 0.69970\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.7176 - accuracy: 0.7486 - val_loss: 0.8753 - val_accuracy: 0.6958\n",
      "Epoch 48/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.7083 - accuracy: 0.7534\n",
      "Epoch 48: val_accuracy improved from 0.69970 to 0.70700, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.7084 - accuracy: 0.7533 - val_loss: 0.8473 - val_accuracy: 0.7070\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.7527\n",
      "Epoch 49: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.7039 - accuracy: 0.7527 - val_loss: 0.8521 - val_accuracy: 0.7046\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.7552\n",
      "Epoch 50: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6971 - accuracy: 0.7552 - val_loss: 0.8498 - val_accuracy: 0.7039\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.7568\n",
      "Epoch 51: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6922 - accuracy: 0.7568 - val_loss: 0.8586 - val_accuracy: 0.7013\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.7598\n",
      "Epoch 52: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6889 - accuracy: 0.7598 - val_loss: 0.9001 - val_accuracy: 0.6891\n",
      "Epoch 53/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6822 - accuracy: 0.7624\n",
      "Epoch 53: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.6820 - accuracy: 0.7624 - val_loss: 0.8423 - val_accuracy: 0.7066\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7628\n",
      "Epoch 54: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6764 - accuracy: 0.7628 - val_loss: 0.8473 - val_accuracy: 0.7056\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6706 - accuracy: 0.7653\n",
      "Epoch 55: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.6706 - accuracy: 0.7653 - val_loss: 0.8615 - val_accuracy: 0.7022\n",
      "Epoch 56/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.7667\n",
      "Epoch 56: val_accuracy did not improve from 0.70700\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.6684 - accuracy: 0.7666 - val_loss: 0.8577 - val_accuracy: 0.7037\n",
      "Epoch 57/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6600 - accuracy: 0.7672\n",
      "Epoch 57: val_accuracy improved from 0.70700 to 0.70720, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.6598 - accuracy: 0.7673 - val_loss: 0.8455 - val_accuracy: 0.7072\n",
      "Epoch 58/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7688\n",
      "Epoch 58: val_accuracy improved from 0.70720 to 0.70760, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6590 - accuracy: 0.7688 - val_loss: 0.8472 - val_accuracy: 0.7076\n",
      "Epoch 59/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.7727\n",
      "Epoch 59: val_accuracy did not improve from 0.70760\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6483 - accuracy: 0.7728 - val_loss: 0.8558 - val_accuracy: 0.7033\n",
      "Epoch 60/100\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.6488 - accuracy: 0.7721\n",
      "Epoch 60: val_accuracy improved from 0.70760 to 0.71070, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6481 - accuracy: 0.7724 - val_loss: 0.8424 - val_accuracy: 0.7107\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.7771\n",
      "Epoch 61: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6363 - accuracy: 0.7771 - val_loss: 0.8418 - val_accuracy: 0.7098\n",
      "Epoch 62/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.6370 - accuracy: 0.7773\n",
      "Epoch 62: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6375 - accuracy: 0.7768 - val_loss: 0.8586 - val_accuracy: 0.7047\n",
      "Epoch 63/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6277 - accuracy: 0.7793\n",
      "Epoch 63: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6278 - accuracy: 0.7793 - val_loss: 0.8499 - val_accuracy: 0.7084\n",
      "Epoch 64/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6249 - accuracy: 0.7811\n",
      "Epoch 64: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6251 - accuracy: 0.7811 - val_loss: 0.8604 - val_accuracy: 0.7029\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.7834\n",
      "Epoch 65: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6212 - accuracy: 0.7834 - val_loss: 0.8436 - val_accuracy: 0.7106\n",
      "Epoch 66/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6219 - accuracy: 0.7813\n",
      "Epoch 66: val_accuracy did not improve from 0.71070\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6218 - accuracy: 0.7813 - val_loss: 0.8749 - val_accuracy: 0.7018\n",
      "Epoch 67/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.6078 - accuracy: 0.7881\n",
      "Epoch 67: val_accuracy improved from 0.71070 to 0.71270, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6076 - accuracy: 0.7882 - val_loss: 0.8459 - val_accuracy: 0.7127\n",
      "Epoch 68/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.7887\n",
      "Epoch 68: val_accuracy did not improve from 0.71270\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6070 - accuracy: 0.7885 - val_loss: 0.8710 - val_accuracy: 0.7021\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7862\n",
      "Epoch 69: val_accuracy improved from 0.71270 to 0.71440, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6071 - accuracy: 0.7862 - val_loss: 0.8442 - val_accuracy: 0.7144\n",
      "Epoch 70/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.7899\n",
      "Epoch 70: val_accuracy did not improve from 0.71440\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5990 - accuracy: 0.7899 - val_loss: 0.8536 - val_accuracy: 0.7093\n",
      "Epoch 71/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5960 - accuracy: 0.7907\n",
      "Epoch 71: val_accuracy did not improve from 0.71440\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.5961 - accuracy: 0.7907 - val_loss: 0.8549 - val_accuracy: 0.7101\n",
      "Epoch 72/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.7905\n",
      "Epoch 72: val_accuracy did not improve from 0.71440\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5932 - accuracy: 0.7904 - val_loss: 0.8545 - val_accuracy: 0.7084\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.7935\n",
      "Epoch 73: val_accuracy did not improve from 0.71440\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5896 - accuracy: 0.7935 - val_loss: 0.8440 - val_accuracy: 0.7135\n",
      "Epoch 74/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 0.7939\n",
      "Epoch 74: val_accuracy did not improve from 0.71440\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5836 - accuracy: 0.7940 - val_loss: 0.8675 - val_accuracy: 0.7075\n",
      "Epoch 75/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.7963\n",
      "Epoch 75: val_accuracy improved from 0.71440 to 0.71530, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5820 - accuracy: 0.7964 - val_loss: 0.8487 - val_accuracy: 0.7153\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.7941\n",
      "Epoch 76: val_accuracy did not improve from 0.71530\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5839 - accuracy: 0.7941 - val_loss: 0.8885 - val_accuracy: 0.7015\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7979\n",
      "Epoch 77: val_accuracy improved from 0.71530 to 0.71710, saving model to CIFAR.h5\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.5746 - accuracy: 0.7979 - val_loss: 0.8479 - val_accuracy: 0.7171\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8016\n",
      "Epoch 78: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.5680 - accuracy: 0.8016 - val_loss: 0.8598 - val_accuracy: 0.7116\n",
      "Epoch 79/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.8009\n",
      "Epoch 79: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 10s 30ms/step - loss: 0.5661 - accuracy: 0.8009 - val_loss: 0.8572 - val_accuracy: 0.7108\n",
      "Epoch 80/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5640 - accuracy: 0.8005\n",
      "Epoch 80: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.5641 - accuracy: 0.8007 - val_loss: 0.8488 - val_accuracy: 0.7130\n",
      "Epoch 81/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5566 - accuracy: 0.8044\n",
      "Epoch 81: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.5567 - accuracy: 0.8044 - val_loss: 0.8678 - val_accuracy: 0.7102\n",
      "Epoch 82/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5555 - accuracy: 0.8030\n",
      "Epoch 82: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5556 - accuracy: 0.8030 - val_loss: 0.8715 - val_accuracy: 0.7100\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.8035\n",
      "Epoch 83: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.5576 - accuracy: 0.8035 - val_loss: 0.8574 - val_accuracy: 0.7122\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.8066\n",
      "Epoch 84: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5478 - accuracy: 0.8066 - val_loss: 0.8556 - val_accuracy: 0.7166\n",
      "Epoch 85/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.8092\n",
      "Epoch 85: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5429 - accuracy: 0.8091 - val_loss: 0.8770 - val_accuracy: 0.7101\n",
      "Epoch 86/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.8094\n",
      "Epoch 86: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5423 - accuracy: 0.8094 - val_loss: 0.8709 - val_accuracy: 0.7086\n",
      "Epoch 87/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.8104\n",
      "Epoch 87: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.5402 - accuracy: 0.8104 - val_loss: 0.9131 - val_accuracy: 0.7016\n",
      "Epoch 88/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.8116\n",
      "Epoch 88: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5367 - accuracy: 0.8118 - val_loss: 0.8584 - val_accuracy: 0.7137\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.8128\n",
      "Epoch 89: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5335 - accuracy: 0.8128 - val_loss: 0.8766 - val_accuracy: 0.7086\n",
      "Epoch 90/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8141\n",
      "Epoch 90: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5307 - accuracy: 0.8141 - val_loss: 0.8641 - val_accuracy: 0.7134\n",
      "Epoch 91/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.8111\n",
      "Epoch 91: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5290 - accuracy: 0.8110 - val_loss: 0.9483 - val_accuracy: 0.6963\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8134\n",
      "Epoch 92: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.5232 - accuracy: 0.8134 - val_loss: 0.8708 - val_accuracy: 0.7134\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.8189\n",
      "Epoch 93: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.5202 - accuracy: 0.8189 - val_loss: 0.8632 - val_accuracy: 0.7150\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8165\n",
      "Epoch 94: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5168 - accuracy: 0.8165 - val_loss: 0.8741 - val_accuracy: 0.7137\n",
      "Epoch 95/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5194 - accuracy: 0.8165\n",
      "Epoch 95: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5198 - accuracy: 0.8164 - val_loss: 0.8871 - val_accuracy: 0.7121\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.8212\n",
      "Epoch 96: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5075 - accuracy: 0.8212 - val_loss: 0.8860 - val_accuracy: 0.7149\n",
      "Epoch 97/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.8214\n",
      "Epoch 97: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.5092 - accuracy: 0.8213 - val_loss: 0.8804 - val_accuracy: 0.7141\n",
      "Epoch 98/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.8230\n",
      "Epoch 98: val_accuracy did not improve from 0.71710\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.5059 - accuracy: 0.8231 - val_loss: 0.8796 - val_accuracy: 0.7132\n",
      "Epoch 99/100\n",
      "155/313 [=============>................] - ETA: 2s - loss: 0.5026 - accuracy: 0.8235"
     ]
    }
   ],
   "source": [
    "modelsaved = train(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = modelsaved.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy: %.2f\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7404f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = modelsaved.predict(x_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1726e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, y_pred , normalize='pred')\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
